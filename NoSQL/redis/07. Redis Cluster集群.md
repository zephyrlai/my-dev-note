# Redis Cluster 集群
## 一、概述：
1. 自动将数据进行分片，每个master上放一部分数据
2. 提供内置的高可用支持，部分master不可用时，还是可以继续工作的
3. 在redis cluster架构下，每个redis要放开两个端口号（第二个端口由redis自动配置），比如一个是6379，另外一个就是加10000的端口号，比如16379；16379端口号是用来进行节点间通信的，也就是集群总线（cluster bus）。cluster bus的通信，用来进行故障检测、配置更新、故障转移授权等。cluster bus用了另外一种二进制的协议，主要用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间
4. redis cluster模式下，不建议做物理的读写分离了，建议通过master的水平扩容，来横向扩展读写吞吐量，并支撑更多的海量数据
搭建3主3从架构的cluster集群：

## 二、Cluster集群搭建
### 1. 搭建并启动6个redis单机服务（端口号分别是：6381、6382、6383、6384、6385、6386，下面以7001端口号的节点为例进行搭建）
* 新增配置文件：将原redis源码目录下```redis.conf```在原目录下拷贝一份命名为```6381.conf```，并调整如下配置
    ``` sh
        # 绑定ip  
        bind 192.168.2.151 127.0.0.1  
        # 端口号  
        port 6381    
        # 后台启动    
        daemonize	yes	    
        # pid文件					    
        pidfile		/var/run/redis_7001.pid     
        # 持久化文件目录						    
        dir 		/var/redis/data/6381	    
        # 日志文件目录    
        logfile 	/var/redis/logs/6381.log    
        # 开启cluster模式    
        cluster-enabled yes    
        # 配置cluster配置文件的路径（该配置文件由redis自己新建并维护）    
        cluster-config-file /etc/redis-cluster/node-7001.conf  
        # cluster节点超时时间（超时失联，则认为宕机）  
        cluster-node-timeout 15000	 
        # 如果有replicaof配置（之前做过主备切换的slave节点），需要手动删除或注释掉 
    ```
* 根据配置新建对应的rdb目录、log目录、cluster配置文件目录
* 新建批量启动脚本：start-cluster.sh， 并新增用户可执行权限 ```chmod u+x start-cluster.sh```
    ``` sh
        ./redis-server 6381.conf
        ./redis-server 6382.conf
        ./redis-server 6383.conf
        ./redis-server 6384.conf
        ./redis-server 6385.conf
        ./redis-server 6386.conf
    ```
* 运行启动脚本：```./start-cluster.sh```

### 2. 将6个节点组成cluster集群
* 将已有的6个redis服务配置成cluster集群
    ``` sh
        ./redis-cli --cluster create 192.168.2.151:6381  192.168.2.151:6382  192.168.2.151:6383  192.168.2.151:6384  192.168.2.151:6385  192.168.2.151:6386 --cluster-replicas 1
    ```
    控制台输出：  
    ``` sh
        [root@localhost bin]# ./redis-cli --cluster create 192.168.2.151:6381  192.168.2.151:6382  192.168.2.151:6383 192.168.2.151:6384  192.168.2.151:6385  192.168.2.151:6386 --cluster-replicas 1  
        >>> Performing hash slots allocation on 6 nodes...  
        Master[0] -> Slots 0 - 5460  
        Master[1] -> Slots 5461 - 10922  
        Master[2] -> Slots 10923 - 16383  
        Adding replica 192.168.2.151:6385 to 192.168.2.151:6381  
        Adding replica 192.168.2.151:6386 to 192.168.2.151:6382  
        Adding replica 192.168.2.151:6384 to 192.168.2.151:6383  
        >>> Trying to optimize slaves allocation for anti-affinity  
        [WARNING] Some slaves are in the same host as their master  
        M:  263112bf6e5fa85e1681ea0cb553dcd111f6e412 192.168.2.151:6381     
            slots:[0-5460] (5461 slots) master   
        M:  1b0857a0422f385e6b904c4c6eccc212bc0cbf69 192.168.2.151:6382   
            slots:[5461-10922] (5462 slots) master   
        M:  0644cedadba126aa49d8abf5ffcb045ed94bc3fe 192.168.2.151:6383   
            slots:[10923-16383] (5461 slots) master      
        S:  e1fbad287960a65ce191f23be234128d4600b891 192.168.2.151:6384      
            replicates 0644cedadba126aa49d8abf5ffcb045ed94bc3fe      
        S:  977624ad63ff45fe3f26095c9f8e67404229a2c1 192.168.2.151:6385      
            replicates 263112bf6e5fa85e1681ea0cb553dcd111f6e412      
        S:  4c23e9e992f7eccb2cf596873e743a6cc452f532 192.168.2.151:6386      
            replicates 1b0857a0422f385e6b904c4c6eccc212bc0cbf69      
        Can I set the above configuration? (type 'yes' to accept): yes   
        >>> Nodes configuration updated   
        >>> Assign a different config epoch to each node   
        >>> Sending CLUSTER MEET messages to join the cluster   
        Waiting for the cluster to join     
        ......    
        >>> Performing Cluster Check (using node 192.168.2.151:6381)    
        M:  263112bf6e5fa85e1681ea0cb553dcd111f6e412 192.168.2.151:6381    
            slots:[0-5460] (5461 slots) master    
            1 additional replica(s)    
        M:  0644cedadba126aa49d8abf5ffcb045ed94bc3fe 127.0.0.1:6383    
            slots:[10923-16383] (5461 slots) master    
            1 additional replica(s)      
        M:  1b0857a0422f385e6b904c4c6eccc212bc0cbf69 127.0.0.1:6382      
            slots:[5461-10922] (5462 slots) master      
            1 additional replica(s)      
        S:  e1fbad287960a65ce191f23be234128d4600b891 127.0.0.1:6384      
            slots: (0 slots) slave      
            replicates 0644cedadba126aa49d8abf5ffcb045ed94bc3fe      
        S:  977624ad63ff45fe3f26095c9f8e67404229a2c1 127.0.0.1:6385      
            slots: (0 slots) slave      
            replicates 263112bf6e5fa85e1681ea0cb553dcd111f6e412    
        S:  4c23e9e992f7eccb2cf596873e743a6cc452f532 127.0.0.1:6386    
            slots: (0 slots) slave    
        replicates 1b0857a0422f385e6b904c4c6eccc212bc0cbf69  
        [OK] All nodes agree about slots configuration.  
        >>> Check for open slots...  
        >>> Check slots coverage...  
        [OK] All 16384 slots covered.  
        ```
    ```
* 检查cluster 集群状况： 
    * 方式一：（推荐）命令查看（控制台输出略）
    ``` sh
        redis-cli --cluster check 192.168.2.151：6381
    ```
    * 方式二：连接到cluster集群查看：  
        添加```-c```参数连接到集群，```cluster info```可用于查看集群信息， ```cluster nodes```可用于查看集群节点信息
        控制台输出：
        ``` sh
        [root@localhost bin]# ./redis-cli -c -p 6381
        127.0.0.1:6381> cluster info
        cluster_state:ok
        cluster_slots_assigned:16384
        cluster_slots_ok:16384
        cluster_slots_pfail:0
        cluster_slots_fail:0
        cluster_known_nodes:6
        cluster_size:3
        cluster_current_epoch:6
        cluster_my_epoch:1
        cluster_stats_messages_ping_sent:68
        cluster_stats_messages_pong_sent:71
        cluster_stats_messages_sent:139
        cluster_stats_messages_ping_received:66
        cluster_stats_messages_pong_received:68
        cluster_stats_messages_meet_received:5
        cluster_stats_messages_received:139
        127.0.0.1:6381> cluster nodes
        0644cedadba126aa49d8abf5ffcb045ed94bc3fe 127.0.0.1:6383@16383 master - 0 1571314879297 3 connected 10923-16383
        1b0857a0422f385e6b904c4c6eccc212bc0cbf69 127.0.0.1:6382@16382 master - 0 1571314881312 2 connected 5461-10922
        e1fbad287960a65ce191f23be234128d4600b891 127.0.0.1:6384@16384 slave 0644cedadba126aa49d8abf5ffcb045ed94bc3fe 0 1571314880303 4 connected
        977624ad63ff45fe3f26095c9f8e67404229a2c1 127.0.0.1:6385@16385 slave 263112bf6e5fa85e1681ea0cb553dcd111f6e412 0 1571314880000 5 connected
        263112bf6e5fa85e1681ea0cb553dcd111f6e412 192.168.2.151:6381@16381 myself,master - 0 1571314879000 1 connected 0-5460
        4c23e9e992f7eccb2cf596873e743a6cc452f532 127.0.0.1:6386@16386 slave 1b0857a0422f385e6b904c4c6eccc212bc0cbf69 0 1571314878286 6 connected
        127.0.0.1:6381> set k1 v1
        -> Redirected to slot [12706] located at 127.0.0.1:6383
        OK
        127.0.0.1:6383> set k2 v2
        -> Redirected to slot [449] located at 127.0.0.1:6381
        OK
        127.0.0.1:6381> get k2
        "v2"
        127.0.0.1:6381> get k1
        -> Redirected to slot [12706] located at 127.0.0.1:6383
        "v1"
        127.0.0.1:6383>
        ```

## 三、Cluster集群水平扩容与缩容
### 1. 扩容
* 新增一台cluster的master主节点
    * 单机配置一台cluster的redis节点（6387）并启动（与上面的配置一样，略）
    * 将6387节点添加到集群：
        ``` sh
            ./redis-cli --cluster add-node 192.168.2.151:6387 192.168.2.151:6381
        ```
    * 查看最新的集群信息（可以看到6387没有分配数据插槽slot）：
        ``` sh
            [root@localhost bin]# ./redis-cli --cluster check 192.168.2.151:6381  
            192.168.2.151:6381 (263112bf...) -> 1 keys | 5461 slots | 1 slaves.  
            127.0.0.1:6387 (152f7f29...) -> 0 keys | 0 slots | 0 slaves.  
            127.0.0.1:6383 (0644ceda...) -> 1 keys | 5461 slots | 1 slaves.  
            127.0.0.1:6382 (1b0857a0...) -> 0 keys | 5461 slots | 1 slaves.  
            [OK] 2 keys in 4 masters.  
            0.00 keys per slot on average.  
            >>> Performing Cluster Check (using node 192.168.2.151:6381)  
            M:  263112bf6e5fa85e1681ea0cb553dcd111f6e412 192.168.2.151:6381  
                slots:[0-5460] (4096 slots) master  
                1 additional replica(s)  
            M:  152f7f29a148d9dc3e33594fc6c4bb7f0c65db58 127.0.0.1:6387  
                slots: (4096 slots) master  
            M:  0644cedadba126aa49d8abf5ffcb045ed94bc3fe 127.0.0.1:6383  
                slots:[10923-16383] (4096 slots) master  
                1 additional replica(s)  
            M:  1b0857a0422f385e6b904c4c6eccc212bc0cbf69 127.0.0.1:6382  
                slots:[5461-10922] (4096 slots) master  
                1 additional replica(s)  
            S:  e1fbad287960a65ce191f23be234128d4600b891 127.0.0.1:6384  
                slots: (0 slots) slave  
                replicates 0644cedadba126aa49d8abf5ffcb045ed94bc3fe  
            S:  977624ad63ff45fe3f26095c9f8e67404229a2c1 127.0.0.1:6385  
                slots: (0 slots) slave  
                replicates 263112bf6e5fa85e1681ea0cb553dcd111f6e412  
            S:  4c23e9e992f7eccb2cf596873e743a6cc452f532 127.0.0.1:6386  
                slots: (0 slots) slave  
                replicates 1b0857a0422f385e6b904c4c6eccc212bc0cbf69  
            [OK] All nodes agree about slots configuration.  
            >>> Check for open slots...  
            >>> Check slots coverage...  
            [OK] All 16384 slots covered.  
        ```
    * 手动重新分配集群的slot(控制台输出太长，此处略)： 
        ``` sh
            # redis-cli --cluster reshard 集群名称
            ./redis-cli --cluster reshard 192.168.2.151:6387
            # 输入先要移入新节点的slot数量：4096
            # 输入接收slot的节点id
            # 依次输入slot的来源节点（输入all表示全部，输入done结束）
        ```
    * 重新查看集群信息，可以看到整个集群的slot已重新分配：
        ``` sh
            [root@localhost bin]# ./redis-cli --cluster check 192.168.2.151:6381  
            192.168.2.151:6381 (263112bf...) -> 0 keys | 4096 slots | 1 slaves.  
            127.0.0.1:6387 (152f7f29...) -> 1 keys | 4096 slots | 0 slaves.  
            127.0.0.1:6383 (0644ceda...) -> 1 keys | 4096 slots | 1 slaves.  
            127.0.0.1:6382 (1b0857a0...) -> 0 keys | 4096 slots | 1 slaves.  
            [OK] 2 keys in 4 masters.  
            0.00 keys per slot on average.  
            >>> Performing Cluster Check (using node 192.168.2.151:6381)  
            M:  263112bf6e5fa85e1681ea0cb553dcd111f6e412 192.168.2.151:6381  
                slots:[1365-5460] (4096 slots) master  
                1 additional replica(s)  
            M:  152f7f29a148d9dc3e33594fc6c4bb7f0c65db58 127.0.0.1:6387  
                slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master  
            M:  0644cedadba126aa49d8abf5ffcb045ed94bc3fe 127.0.0.1:6383  
                slots:[12288-16383] (4096 slots) master  
                1 additional replica(s)  
            M:  1b0857a0422f385e6b904c4c6eccc212bc0cbf69 127.0.0.1:6382  
                slots:[6827-10922] (4096 slots) master  
                1 additional replica(s)  
            S:  e1fbad287960a65ce191f23be234128d4600b891 127.0.0.1:6384  
                slots: (0 slots) slave  
                replicates 0644cedadba126aa49d8abf5ffcb045ed94bc3fe  
            S:  977624ad63ff45fe3f26095c9f8e67404229a2c1 127.0.0.1:6385  
                slots: (0 slots) slave  
                replicates 263112bf6e5fa85e1681ea0cb553dcd111f6e412  
            S:  4c23e9e992f7eccb2cf596873e743a6cc452f532 127.0.0.1:6386  
                slots: (0 slots) slave  
                replicates 1b0857a0422f385e6b904c4c6eccc212bc0cbf69  
            [OK] All nodes agree about slots configuration.  
            >>> Check for open slots...  
            >>> Check slots coverage...  
            [OK] All 16384 slots covered.  
        ```
* 新增一台cluster的slave节点
    * 单机配置一台cluster的redis节点（6388）并启动（与上面的配置一样，略）
    * 将6388节点添加到集群（指定为6387的slave node）：
        ``` sh
            ./redis-cli --cluster add-node --cluster-slave --cluster-master-id 152f7f29a148d9dc3e33594fc6c4bb7f0c65db58 192.168.2.151:6388 192.168.2.151:6381
        ```
    * 再次查看集群信息，可以看到6388已经是6387的slave node
        ``` sh
            [root@localhost bin]# ./redis-cli --cluster check 192.168.2.151:6381  
            192.168.2.151:6381 (263112bf...) -> 0 keys | 4096 slots | 1 slaves.  
            127.0.0.1:6387 (152f7f29...) -> 1 keys | 4096 slots | 1 slaves.  
            127.0.0.1:6383 (0644ceda...) -> 1 keys | 4096 slots | 1 slaves.  
            127.0.0.1:6382 (1b0857a0...) -> 0 keys | 4096 slots | 1 slaves.  
            [OK] 2 keys in 4 masters.  
            0.00 keys per slot on average.  
            >>> Performing Cluster Check (using node 192.168.2.151:6381)  
            M:  263112bf6e5fa85e1681ea0cb553dcd111f6e412 192.168.2.151:6381  
                slots:[1365-5460] (4096 slots) master  
                1 additional replica(s)  
            M:  152f7f29a148d9dc3e33594fc6c4bb7f0c65db58 127.0.0.1:6387  
                slots:[0-1364],[5461-6826],[10923-12287] (4096 slots) master  
                1 additional replica(s)  
            S:  f841bec7467753520c9dbd8df4678deb0baa3fa8 127.0.0.1:6388  
                slots: (0 slots) slave  
                replicates 152f7f29a148d9dc3e33594fc6c4bb7f0c65db58  
            M:  0644cedadba126aa49d8abf5ffcb045ed94bc3fe 127.0.0.1:6383  
                slots:[12288-16383] (4096 slots) master  
                1 additional replica(s)  
            M:  1b0857a0422f385e6b904c4c6eccc212bc0cbf69 127.0.0.1:6382  
                slots:[6827-10922] (4096 slots) master  
                1 additional replica(s)  
            S:  e1fbad287960a65ce191f23be234128d4600b891 127.0.0.1:6384  
                slots: (0 slots) slave  
                replicates 0644cedadba126aa49d8abf5ffcb045ed94bc3fe  
            S:  977624ad63ff45fe3f26095c9f8e67404229a2c1 127.0.0.1:6385  
                slots: (0 slots) slave  
                replicates 263112bf6e5fa85e1681ea0cb553dcd111f6e412  
            S:  4c23e9e992f7eccb2cf596873e743a6cc452f532 127.0.0.1:6386  
                slots: (0 slots) slave  
                replicates 1b0857a0422f385e6b904c4c6eccc212bc0cbf69  
            [OK] All nodes agree about slots configuration.  
            >>> Check for open slots...  
            >>> Check slots coverage...  
            [OK] All 16384 slots covered.  
        ```
### 2. 缩容
* 先用```reshard```将6381节点的数据都移除到其他节点（确保node为空之后，才能执行删除操作，依次向6387、6382、6382迁移1365、1365、1366个slot）,迁移完成之后，集群信息如下：
    ``` sh
        [root@localhost bin]# ./redis-cli --cluster check 192.168.2.151:6381  
        192.168.2.151:6381 (263112bf...) -> 0 keys | 0 slots | 0 slaves.  
        127.0.0.1:6387 (152f7f29...) -> 1 keys | 5461 slots | 1 slaves.  
        127.0.0.1:6383 (0644ceda...) -> 1 keys | 5462 slots | 2 slaves.  
        127.0.0.1:6382 (1b0857a0...) -> 0 keys | 5461 slots | 1 slaves.  
        [OK] 2 keys in 4 masters.  
        0.00 keys per slot on average.  
        >>> Performing Cluster Check (using node 192.168.2.151:6381)  
        M:  263112bf6e5fa85e1681ea0cb553dcd111f6e412 192.168.2.151:6381    
            slots: (0 slots) master    
        M:  152f7f29a148d9dc3e33594fc6c4bb7f0c65db58 127.0.0.1:6387    
            slots:[0-2729],[5461-6826],[10923-12287] (5461 slots) master    
            1 additional replica(s)    
        S:  f841bec7467753520c9dbd8df4678deb0baa3fa8 127.0.0.1:6388      
            slots: (0 slots) slave      
            replicates 152f7f29a148d9dc3e33594fc6c4bb7f0c65db58      
        M:  0644cedadba126aa49d8abf5ffcb045ed94bc3fe 127.0.0.1:6383      
            slots:[4095-5460],[12288-16383] (5462 slots) master      
            2 additional replica(s)      
        M:  1b0857a0422f385e6b904c4c6eccc212bc0cbf69 127.0.0.1:6382      
            slots:[2730-4094],[6827-10922] (5461 slots) master      
            1 additional replica(s)      
        S:  e1fbad287960a65ce191f23be234128d4600b891 127.0.0.1:6384    
            slots: (0 slots) slave    
            replicates 0644cedadba126aa49d8abf5ffcb045ed94bc3fe    
        S:  977624ad63ff45fe3f26095c9f8e67404229a2c1 127.0.0.1:6385    
            slots: (0 slots) slave    
            replicates 0644cedadba126aa49d8abf5ffcb045ed94bc3fe    
        S:  4c23e9e992f7eccb2cf596873e743a6cc452f532 127.0.0.1:6386    
            slots: (0 slots) slave    
        replicates 1b0857a0422f385e6b904c4c6eccc212bc0cbf69  
        [OK] All nodes agree about slots configuration.  
        >>> Check for open slots...  
        >>> Check slots coverage...  
        [OK] All 16384 slots covered.  
    ```
* 删除节点信息
    ``` sh
        redis-cli --cluster del-node 192.168.2.151:6387 152f7f29a148d9dc3e33594fc6c4bb7f0c65db58
    ```
### 3. 关闭集群
* 新建脚本文件：shutdown-cluster.sh
    ``` sh
        ./redis-cli -p 6381 shutdown
        ./redis-cli -p 6382 shutdown
        ./redis-cli -p 6383 shutdown
        ./redis-cli -p 6384 shutdown
        ./redis-cli -p 6385 shutdown
        ./redis-cli -p 6386 shutdown
        ./redis-cli -p 6387 shutdown
        ./redis-cli -p 6388 shutdown
    ```
* 给脚本添加用户可执行权限
    ``` sh
    chmod u+x shutdown-cluster.sh
    ```
* 执行脚本：
    ``` sh
        ./shutdown-cluster.sh
    ```